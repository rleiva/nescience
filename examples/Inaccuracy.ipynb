{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the Inaccuracy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 10, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastautoml.fastautoml import Inaccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inaccuracy of a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(min_samples_leaf=5)\n",
    "tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inaccuracy()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inacc = Inaccuracy()\n",
    "inacc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17094976238811344"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inacc.inaccuracy_model(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also work directly with the set of predictions, instead of using the model. This allow us to compute the inaccuracy of models not implemented by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tree.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17094976238811344"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inacc.inaccuracy_predictions(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare score with inaccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inaccuracy()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inacc = Inaccuracy()\n",
    "inacc.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a collection of decision tree classifers with different levels of depth, compute a classical score and the new inaccuracy metric, and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores       = list()\n",
    "inaccuracies = list()\n",
    "\n",
    "for i in range(1, 20):\n",
    "    \n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=42)\n",
    "    tree.fit(X, y)\n",
    "    \n",
    "    scores.append(1 - tree.score(X, y))\n",
    "    inaccuracies.append(inacc.inaccuracy_model(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,20), scores, label=\"Score\")\n",
    "plt.plot(range(1,20), inaccuracies, label=\"Inaccuracy\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Tree Depth\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the behaviour of score and inaccuracy when we introduce more errors in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(min_samples_leaf=5, random_state=42)\n",
    "tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inacc.fit(X, y)\n",
    "inacc.inaccuracy_model(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - tree.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens if we make one hundred times the same error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2     = X.copy()\n",
    "y2     = y.copy()\n",
    "for i in np.arange(100):\n",
    "    X2 = np.append(X2, [X[0]], axis=0)\n",
    "    y2 = np.append(y2, (y[0]+1) % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inacc.fit(X2, y2)\n",
    "inacc.inaccuracy_model(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - tree.score(X2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The theory of nescience states that making one hundred times the same error is not that bad. Let's see what happens if we make one hundred different errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3     = X.copy()\n",
    "y3     = y.copy()\n",
    "for i in np.arange(100):\n",
    "    index  = np.random.randint(X.shape[0])\n",
    "    X3     = np.append(X3, [X[index]], axis=0)\n",
    "    y3     = np.append(y3, (y[index]+1) % 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inacc.fit(X3, y3)\n",
    "inacc.inaccuracy_model(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - tree.score(X3, y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making one hundred different errors is worse than making one hundred times the same error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the behaviour of score and inaccuracy in a hihgly imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = list()\n",
    "score = list()\n",
    "inacc = list()\n",
    "\n",
    "inaccuracy = Inaccuracy()\n",
    "\n",
    "for i in np.arange(1, 100):\n",
    "                    \n",
    "    X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0,\n",
    "                               class_sep=2, flip_y=0, weights=[0.95,0.05])\n",
    "\n",
    "    inaccuracy.fit(X, y)\n",
    "        \n",
    "    tree = DecisionTreeClassifier(min_samples_leaf=i)\n",
    "    tree.fit(X, y)\n",
    "\n",
    "    depth.append(i)        \n",
    "    score.append(1 - tree.score(X, y))\n",
    "    inacc.append(inaccuracy.inaccuracy_model(tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(depth, score, label=\"Score\")\n",
    "plt.plot(depth, inacc, label=\"Inaccuracy\")\n",
    "plt.title(\"Isotropic Gaussian Blobs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Minimum Leaf Size\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the score metric is not able to work with imbalanced datasts, a problem that is not suffered by the new inaccuracy metric."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
